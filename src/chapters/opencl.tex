\chapter{OpenCL}

\todo{kernel examples}

\section{General description}
OpenCL can accommodate easily and efficiently a wide range of devices. It achieves this by providing a low-level abstraction layer (consisting of a subset of the \cstd standard with extensions for parallelism and a great number of built-in functions), as well as a runtime system. These are designed to be as close to the hardware as possible, but without losing portability. Naturally, it is unlikely that code tuned for one platform will be optimal on all the others, so application tuning is still necessary for each platform of interest. However, the advantage of using OpenCL is that it provides a uniform API, and one that, due to its close relationship with C, is easy for most programmers to get comfortable with.

Thanks to the great support that it is getting from several major companies (including Apple, Intel, AMD, IBM) and also to the growing popularity of GPGPU, OpenCL is starting to become more and more visible. Many of these companies are releasing SDKs that allow programmers to write OpenCL applications for their devices: NVIDIA, AMD and ARM for their GPUs, IBM for the Cell broadband engine, Qualcomm for their Snapdragon SoC family, Adapteva for their Epiphany floating point accelerator, and so forth. In fact, OpenCL support is included by default in Mac OS X since Snow Leopard\cite{http://www.apple.com/pr/library/2008/06/09Apple-Previews-Mac-OS-X-Snow-Leopard-to-Developers.html}, while Altera has adopted OpenCL for their FPGA devices\cite{http://www.altera.com/literature/wp/wp-01173-opencl.pdf}, hinting at a possible dethronement of the HDL languages (such as Verilog and VHDL) previously used to program them.

Besides all the SDKs, there have also surfaced various other tools to aid developers. Some examples include: 
\begin{itemize}
\item OpenCL Studio - an IDE \cite{http://www.opencldev.com/}
\item OpenCL CodeBench - an Eclipse based IDE (with wizards that facilitate the writing of OpenCL host code, unit tests and sample data) \cite{http://www.amdahlsoftware.com/multi-core-products/overview/}
\item AMD CodeXL - debugger and profiler \cite {http://developer.amd.com/tools/hc/CodeXL/}
\item AMD ocl-emu - tool that allows programmers to compile and debug OpenCL kernels as C++ procedures in Microsoft Visual Studio \cite{http://developer.amd.com/tools-and-sdks/open-source/opencl-emulator-debugger/}
\item various language bindings and wrappers, such as Aparapi\cite{http://code.google.com/p/aparapi}, JogAmp\cite{http://jogamp.org/} and the Lightweight Java Game Library\cite{http://www.lwjgl.org/} (for Java), PyOpenCL\cite{http://mathema.tician.de/software/pyopencl/} and CLyther\cite{http://srossross.github.io/Clyther/} (for Python), Cloo\cite{http://sourceforge.net/projects/cloo/} and The Open Toolkit library\cite{http://sourceforge.net/projects/opentk/} (for C\#) etc.
\end{itemize}

All this enthusiasm has resulted in OpenCL being adopted for several applications, usually as an alternative to CUDA. To name a few:
\begin{itemize}
\item Adobe Photoshop CS6\cite{http://helpx.adobe.com/photoshop/kb/photoshop-cs6-gpu-faq.html} and Adobe Premiere CS6\cite{http://blogs.adobe.com/premierepro/2012/05/opencl-and-premiere-pro-cs6.html}
\item VLC Media Player\cite{http://openclnews.com/apps/vlc_media_player}
\item GIMP\cite{http://www.gimp.org/}
\item some versions of Blender\cite{http://www.atmind.nl/?p=35}
\item WinZip\cite{http://www.tomshardware.com/reviews/winrar-winzip-7-zip-magicrar}
\item The OpenCL H.264/AVC Encoder 2.0\cite{http://www.mainconcept.com/products/sdks/gpu-acceleration/opencltm-h264avc.html}
\item hashcat password cracking utilities (oclHashcat-plus\cite{http://hashcat.net/oclhashcat-plus/}, oclHashcat-lite\cite{http://hashcat.net/oclhashcat-lite/}, oclGaussCrack\cite{http://hashcat.net/oclGaussCrack/})
\item Cryptohaze GPU Rainbow Cracker\cite{https://www.cryptohaze.com/gpurainbowcracker.php}
\item Wolfram Mathematica 8\cite{http://www.wolfram.com/mathematica/new-in-8/cuda-and-opencl-support/}
\item various scientific applications\cite{http://www.sciencedirect.com/science/article/pii/S0010465510001682}\cite{http://arxiv.org/abs/1002.0916}
\end{itemize}
As was to be expected, these projects fall into the range of scientific applications, graphical processing, video processing, password cracking etc. --- all of which have high computational requirements and, of course, good opportunities for parallelism.

The rest of this chapter goes on to a detailed description of the standard, which roughly follows the structure of the OpenCL \oclVersion specification\cite{oclspec}.

\section{The OpenCL runtime and platform layer}
\label{section:runtime}
OpenCL systems consist of a host and one or more devices. The host is usually your run of the mill CPU and acts as a master, managing the general logic of the application as well as the execution of special code sequences (kernels) on the devices. This model is very similar to that of CUDA (which comes as no surprise considering the origins of OpenCL).

A device is usually an accelerator, i.e. a more powerful, specialized processor, such as a GPU, but there also exist several SDKs that allow OpenCL kernels to be run on the CPU (e.g. the Intel SDK\cite{http://software.intel.com/en-us/vcsource/tools/opencl} and the AMD SDK\cite{http://developer.amd.com/tools/heterogeneous-computing/amd-accelerated-parallel-processing-app-sdk/} for the x86 and x64 architectures). 

The devices are divided into one or more compute units, which, in turn, are divided into one or more processing elements (\labelindexref{Figure}{img:ocl-devices}). This model maps perfectly on the common architecture of GPUs, which consist of several multiprocessors (which can act as compute units), each containing a number of cores (processing elements). However, the model is flexible enough to accommodate other structures just as well - for example, in the case of the Cell Broadband Engine, the host is the PowerPC Processing Element (PPE), whereas the device is represented by the Synergistic Processing Elements (SPEs), with each SPE being regarded as a compute unit.
\clearpage

\fig[scale=1]{src/img/ocl-device.JPG}{img:ocl-devices}{OpenCL platform model, as found in the OpenCL \oclVersion specification}

The compute units can also be grouped into non-overlapping subdevices, which can be further used in the same way as the original device. The partitioning can be done in one of several ways: 
\begin{itemize}
\item groups of equal size (with the size provided by the user), 
\item groups of different, user-defined sizes (the user must provide a list of sizes), or, more interestingly, 
\item groups of compute devices that share a certain level in the memory hierarchy (the user can choose between L1 cache, L2, L3, L4 and NUMA node, or ask the API to find the first level at which the device can be partitioned in this way).
\end{itemize}

The OpenCL memory model is highly compatible with its view of the devices. There are several different memory regions:
\begin{itemize} 
\item the private memory (default), which is local to each processing element, 
\item the local memory, belonging to each compute element,
\item the global memory, which can be accessed by both the device and the host, and
\item the constant memory, which is visible to both the device and the host, but for which the device has read-only access.
\end{itemize}
Naturally, the specification makes no assumptions about the physical layout of the memory. It is also important to note that the host memory is separate from these regions, and transfers between the host memory and device memory are done using buffers.

The main focus of OpenCL is the execution of kernels on the device in a way that takes full advantage of any opportunity for parallelism that the device may offer. In order to allow this in a way that is independent of the actual structure and capabilities of the device (number of cores etc.), OpenCL introduces the concept of NDRanges. An NDRange is an N-dimensional index space\footnote{N can be 1, 2 or 3.}. Whenever a kernel is submitted to the device, such an index space is created and the kernel is executed once for each point in it. Each instance of the kernel is called a work-item and has a unique ID representing its point in the NDRange. Each dimension of the work-group contains one or more work-groups, which in turn contain one or more work-items. The work-items have some degree of independency: they run the same code, but not necessarily on the same data (it can depend on the work-item's ID), and thus not necessarily with the same execution path.

There is a tight mapping between this execution model and the general platform model of OpenCL: work-items correspond to processing elements and work-groups to compute units.

The communication between the host and the devices is achieved using command queues. The host can place 3 types of commands:
\begin{itemize}
\item commands that execute kernels on the devices,
\item commands that handle the memory, or 
\item synchronization commands.
\end{itemize}
The commands can be executed on the kernel in order or out of order (depending on a property set by the programmer at the time of the creation of the command queue). For in order execution, the synchronization is implicit: a command is only executed after the previously queued command has ended its execution. For the out of order mode, the API contains synchronization commands such as markers\footnote{A marker is a command that waits either for the commands in a list, or for all the commands previously queued to complete. It returs an event that can be waited on, but does not block execution of subsequent commands.} and barriers\footnote{Like a marker, but it blocks the queue.}. The API provides no means to synchronize between different command queues.

\section{The OpenCL language}
\label{section:ocl-language}
The OpenCL language is the language in which the kernels to be executed on the device are written. It is derived from C, but contains certain extensions and restrictions which are meant to help compilers perform better code optimization for devices with certain capabilities (such as SIMD units).

The most significant extension brought by OpenCL is the introduction of several new data types, collectively referred to as vector data types. These consist of a base type (which can be int, short, double etc.) and a length(2, 3, 4, 8 or 16)\footnote{All the possible combinations yield 50 vector types.}. Vector types support standard mathematical and logical operators, such as +, *, <, ++, \&, \&\& and so on, both with another vector and with a scalar (in which case the scalar is first widened to a vector of the same size). The operation is done component-wise and the result is another vector. It is obvious that machines with SIMD support will benefit greatly from this extension (they only perform one instruction instead of a number of instructions equal to the length of the vector), however all OpenCL devices are required to support this syntax (and produce valid results).

A peculiar kind of vector are vector literals, which are nothing but syntactic sugar for the declaration of a vector as a list of its components\footnote{The syntax looks something like this: int4 x = (int4)(-1, 3, 0, -6).}. Any combination of vectors and scalars that yields the desired number of components is accepted.

Accessing a vector's components can be done in several ways:
\begin{itemize}
\item through the x, y, z, w notation (only for vector with a length less than or equal to 4)
\item through numeric indices prefixed by the letter 's' or 'S' (the numeric indices must be in hexadecimal)
\item through suffixes (valid suffixes are odd, even, hi, lo)
\end{itemize}
Accesses to vector components must return either a vector type or a scalar with the same base type as the initial vector. For the first 2 notations, it is possible to concatenate components in any order and any number of times (such that some\_vector.xyxy is a valid access), and it is also possible to chain multiple levels of suffixes (such as some\_vector.odd.hi).

Another data type supported by OpenCL is the half data type, compliant with the IEEE 754-2008 standard. It allows users to store arrays of half precision floating point values. However, it is only meant to reduce storage - the operations with it are performed using single precision.

The language also adds built-in types for image handling and for synchronization between the work-items inside the same work-group, but these are only manageable through built-in functions (that is, no operators and other syntactic sugar).

The built-in functions offered by OpenCL are manifold; some examples include:
\begin{itemize}
\item Work-item functions - offer the possibility to query about the parameters of the NDRange and about the current work item's position in it
\item Math functions - sin, acos, exp, lgamma (the logarithm of the Gamma function) and many more
\item Integer functions - abs, min, max, rotate (similar to the x86 rol instruction) etc.
\item Functions for converting between radians and degrees, step functions (return 0 if the argument is smaller than a threshold and 1 otherwise) and so on
\item Geometric functions - cross product, dot product, distance etc.
\item Synchronization functions - barrier, memory fence
\item Image read and write functions
\end{itemize}

The language also provides support for the OpenCL memory model, in the form of address space qualifiers\footnote{These are:
\begin{itemize}
\item \_\_global or global
\item \_\_local or local
\item \_\_private or private
\item \_\_constant or constant
\end{itemize}
}. Another set of qualifiers that it provides, but only for image objects, is the set of access qualifiers, enabling the programmer to enforce read-only, write-only or read-write access.

OpenCL also adds a number of preprocessor directives, macros and attributes, but there's no need to go into that much detail here.

The most significant restrictions imposed by the language include:
\begin{itemize}
\item Pointers to functions are not allowed.
\item Pointers to pointers are not allowed as arguments to kernel functions (they may however appear in the kernel body).
\item Pointers from different memory areas cannot be assigned to one another.
\item Recursion is not supported.
\item Variable length arrays, variadic functions and variadic macros are not supported.
\item Kernel functions can only return void.
\item Some standard C99 headers cannot be included by OpenCL programs (e.g. assert.h, errno.h, stdio.h, stdlib.h, string.h etc.).
\end{itemize}

\section{OpenCL alternatives}
\label{section:oclalternatives}
Since OpenCL was initially designed for GPGPU, it is often viewed as a natural competitor to CUDA and DirectCompute. But, while OpenCL is indeed an alternative to these frameworks, the converse is not true: OpenCL is much more general, and therein lies its strength - OpenCL can be ported to any device.

A worthy alternative to OpenCL is Microsoft's C++ AMP (Accelerated Massive Parallelism)\cite{cppamp}. C++ AMP consists of a series of extensions to the C++ language that allow the use of accelerators to run data parallel algorithms. Microsoft provides an implementation for GPUs based on DirectX 11, however the C++ AMP specification is released under the "Community Promise" licence, which allows other implementations. The most interesting one, for the purpose of this thesis, is Intel's Shevlin Park proof of concept implementation, which translates C++ AMP to OpenCL. This approach offers similar or better performance than Microsoft's implementation\cite{shevlin}, because OpenCL provides a better memory model than DirectX. This proves that OpenCL is a valuable tool that can be built on top of.

Other alternatives to OpenCL include:
\begin{itemize}
\item Renderscript, which is used by Android in order to perform computationally intensive tasks
\item the Multicore Association APIs (MCAPI - the Multicore Communications API, MRAPI - the Multicore Resource Management API, MTAPI - the Multicore Task Management API), which are designed to ease the programming of heterogeneous devices
\item OpenMP, which is a popular API, used mostly to express parallelism on CPUs - however, recently there have been efforts to provide an implementation for heterogeneous systems, based on the MCA APIs\cite{libeomp}
\item other APIs designed to express parallelism for multicore devices (Intel Threading Building Blocks, Microsoft's Parallel Patterns Library, Apple's Grand Central Dispatch etc.)
\end{itemize}

It is not the purpose of this thesis to comment on the advantages and disadvantages of each of these alternatives. However, the fact that there are so many of them makes it clear that there is a need for a standard in this domain, and this is what OpenCL is hoping to become. 

%\section{Portability or something... advantages/disadvantages?... comparison with CUDA / DirectCompute?}
%\todo{discuss flexibility: partitioning according to common cache, memory model, native kernels vs ocl kernels; discuss the possibility to query for devices at runtime; discuss tuning...?}

%\todo{Anexa cu device-urile care suporta ocl}
%\todo{Anexa cu functiile built-in}
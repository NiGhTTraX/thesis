\chapter{Compiler implementation}
\label{chapter:compiler}
\todo{more examples of translations to C++ IR - for read / write, operators etc.}

\section{The C++ intermediate representation}
\label{section:IR}
Using C++ as an intermediary between the front end and back end of a compiler is not very common, and indeed in most cases it wouldn't make any sense to use it. The reason why it is a good choice in this case is the fact that most of the OpenCL language can be parsed by the C++ compiler as is - the only things that are different are the OpenCL-specific data types and the operations that can be performed on them\footnote{These have been described in Section \ref{section:ocl-language}.}, which could be implemented as a separate C++ library and linked with a translated version of the original sources.

The most relevant OpenCL data types, at least for the StarCore architecture, are the vector types (e.g. float4). The OpenCL syntax that is related to vector types and that might thus need to be translated into C++ includes:
\begin{itemize}
\item Any reference to the type name - in variable and function declarations, as well as in casts
\item Arithmetic and relational operators between vectors and also between vectors and scalars
\item Vector literals
\item Vector component accesses
\end{itemize}

A natural approach would be to model every vector type as a C++ class. In this case, the necessary transformations of the original sources can be performed as follows:
\begin{itemize}
\item References to the type name can be replaced with references to the corresponding C++ class
\item Arithmetic and relational operators can be overloaded (therefore no actual transformation of the original sources is necessary in order to support them)
\item Vector literals can be replaced with constructor calls
\item Vector component accesses can be replaced with accessor methods
\end{itemize}

This is simple and straightforward, and it also provides an abstraction layer that allows the encapsulation of sundry implementations (either relying on standard C++, or on platform-specific data types and intrinsics) without changing the front end and the transformations that it performs.

But there are also some disadvantages. For one thing, since there are 50 OpenCL vector types, we will need 50 classes, with very similar functionality - practically the only things that are different are the length of the vector and the type of the vector's components. This problem can be solved by means of inheritance, but templates provide a more elegant solution.

Another issue is related to the replacement of vector literals with constructor calls: a vector literal can consist of any combination of vectors and scalars that total the desired number of components. So, for example, an int8 can be constructed from an int4 and 2 int2 in any of the following sequences: (int4, int2, int2), (int2, int4, int2), (int2, int2, int4). Having an overload for each combination would generate an enormous library. The same is true in the case of component accesses: any combination of elements from one vector can be accessed as a separate vector\footnote{The syntax for this looks like vec.yx, where vec is a vector of 2, 3 or 4 elements, and vec.yx is a vector of 2 elements, that can be read or written to. This syntax is described in more detail in section \ref{section:ocl-language}.}. Providing separate accessor methods for each of these combinations would create a lot of code bloat.

With these in mind, the final design of the C++ intermediate representation is as follows: the vectors are represented as a template by the number of elements. Therefore, there is one template for each vector base type\footnote{In this case, whether we have different templates or template specializations for each base type makes little difference.}. This is necessary because different base types dictate slightly different behaviour - for example, the modulo operator can only be applied on vectors with an integer base type\footnote{This means long, int, short, char and their unsigned counterparts.}. A great degree of similarity still exists between these templates, however we have reduced the number of classes from 50 to 10\footnote{This is without counting the template specializations, which, as will be further explained, deal with slightly different issues.}.

Furthermore, the similarity between the templates does not have to be a burden: it is not difficult to write a tool that generates them automatically. Such a tool is described in Appendix \ref{appendix:generator}.

An example of the output generated by this tool can be seen in Appendix \ref{appendix:vectemplate}. The bulk of the implementation is presented in Listing \ref{lst:vectempl} - this is the base template, which covers all the operations that can be performed on an int vector. Most of these are mathematical operations which are implemented by overloading the corresponding operators (in the case of binary operators, both the version between 2 vectors, and that between a vector and a scalar). 

An interesting point about templates can be made here: in C++ templates are often used in order to move certain consistency checks from runtime to compile time. An example of this can be seen in Listing \ref{lst:plusop}.

\begin{lstlisting}[label=lst:plusop, caption=Signature of the plus operator]
template <int length>
class intVector{
	[...]
	intVector<length> operator+(intVector<length> other);
	[...]
};
\end{lstlisting}

The overload of the plus operator takes as its argument an intVector<length> - that is, an instance of the same template with the exact same length. Since this is the only overload of the plus operator between 2 vectors, it is an error to use the plus operator between, for instance, an intVector<2> and an intVector<4>, and this error will be caught by the StarCore compiler. If the length of the vector were stored inside the class, this check would have to be made at runtime, incurring both a performance penalty and a delay in the identification of source code errors\footnote{And that's not to mention that it would increase the size of all vector objects, which is not only inefficient but also contradicts the OpenCL standard.}. The fact that this check is performed by the scc also absolves the OpenCL front end from performing it, thus allowing a lighter implementation. This feature is still useful even if a heavier front end implementation is used, because it can help identify translation errors.

The vector classes also provide a read method and a write method, which allow access to the vector's components. These methods take as an argument the sequence of components that need to be accessed\footnote{This sequence is stored, for all vector types, as an intVector, but any kind of ordered container would do the trick - intVector is preferred only in order to avoid additional library dependencies.}. Since the OpenCL front end knows the exact components that are accessed, this sequence will be a sequence of constants - therefore it is up to the StarCore compiler to optimize the calls to the read and write methods. If these calls are not optimized, there will be a performance penalty. Either way, though, the size of the library is reduced, because there are no overloads for every possible sequence of components that can be accessed.

Another way to minimize the size of the library is to avoid generating constructor overloads for every possible vector literal. This is achieved by overloading the comma operator. The comma operator is a rather obscure C/C++ construct that allows users to chain 2 expressions, such that both get evaluated but only the result of the second one is used. The result of the first expression is discarded, therefore its evaluation is only useful if it has side effects (e.g. assignments, increments etc). Some usage examples for the standard comma operator are presented in Listing \ref{lst:comma}. 

\begin{lstlisting}[label=lst:comma, caption=Comma operator examples]
// Comma operator used in the initialization expression of the for loop.
for (b = iterable.begin(), e = iterable.end(); b != e; ++b)
	[...]

// Comma operator used to avoid braces.
if (some_condition)
	some_var = some_value, other_var = other_value;

if (something_went_wrong)
	return (errno = -ENOMEM, -1);
	
// Comma operator used when passing arguments to a function.
some_func(x, (printf("Calling some_func with %d\n", y), y));
\end{lstlisting}

Except for its uses in the for statement, which are quite commonplace, the comma operator seems to only serve to obfuscate code. Furthermore, there is a known ambiguity between the syntax for the comma operator (which is a valid OpenCL operator) and that for vector literals. For example, for the code in Listing \ref{lst:ambiguity} there are 2 valid interpretations:
\begin{itemize}
\item As an OpenCL vector literal
\item As a comma operator followed by an explicit cast to int4 - all 4 comma-separated expressions are evaluated (in this case to the value of the corresponding int constant), the first 3 are discarded, whereas the fourth is cast to an int4 vector
\end{itemize}

\begin{lstlisting}[label=lst:ambiguity, caption=OpenCL vector literal ambiguity]
int4 u = (int4)(1, 3, 3, 7); // u = {1, 3, 3, 7} or u = {7, 7, 7, 7} ?
\end{lstlisting}
The OpenCL standard does not address this issue, however since vector literals are more specific, it is fair to assume that they take precedence over the other interpretation.

The resemblance between vector literals and comma-separated expressions, as well as the fact that the comma operator is rarely used, makes it natural to overload the comma operator: the result of the first expression, instead of being discarded, will be concatenated with the result of the second expression, in order to form a longer vector.

The overloaded comma operator has the signature presented in Listing \ref{lst:overcomma}. 
\begin{lstlisting}[label=lst:overcomma, caption=Signature of the comma operator]
template <int length>
class intVector{
	[...]
	template <int other_length>
	intVector<length + other_length> operator,(intVector<other_length> other);
	
	intVector<length + 1> operator,(int value)
	[...]
};	
\end{lstlisting}

A problem that appears at this point is that it is not possible to overload operators for the C++ primitive types, therefore a comma between 2 scalars would yield a scalar instead of a vector with 2 components. This issue can be solved by introducing a comma operator between a dummy vector, with zero components, and the vector literal. With this hack, the code from Listing \ref{lst:ambiguity} needs to be transformed as seen in Listing \ref{lst:literal}.

\begin{lstlisting}[label=lst:literal, caption=Translation of an OpenCL vector literal to the C++ IR]
// OpenCL form:
// int4 u = (int4)(1, 3, 3, 7);

// C++ IR form:
intVector<4> u = (intVector<0>(), 1, 3, 3, 7);
\end{lstlisting}

With this syntax, the vector literal is built in several stages, corresponding to the commas: the first comma operator, between a vector with zero components and a scalar, yields a vector with one component; the following comma, between this vector and the next scalar, yields a vector with 2 components; and so forth, until the final vector is obtained. 

\todo{maybe todo: naturally, this has a performance overhead, however it greatly diminishes library size (include math... and maybe some blah about how memory is scarce in embedded systems). }
%The performance cost of doing this will be analysed in Chapter \ref{chapter:results}.

Another aspect that stands out is the internal storage used by the templates: it is a C-style array containing elements of the base type. This means that the implementation sticks to the OpenCL requirement that the size of a vector is the number of elements times the size of the base type\footnote{This is true because there are no virtual methods involved, so the C++ compiler does not add a vtable to our objects.}. However, the internal storage can be replaced with anything else that meets this requirement. An example of this will be discussed in more detail in Chapter \ref{chapter:results}.

The last touches that need to be added in order to make this implementation work smoothly come in the shape of template specializations. There are 2 template specializations, which can be seen in Appendix \ref{appendix:vectemplate}:
\begin{itemize}
\item A dummy template, with zero components (Listing \ref{lst:dummytempl}) - this is needed for the comma operator hack. The reason why it must stand as a template specialization is that C++ does not allow C-style arrays with zero elements.
\item A scalar template, with a single component (Listing \ref{lst:scalartempl}) - this is needed in order to provide a simple, uniform interaction between vectors and scalars. It doesn't overload any of the mathematical operators, but contains instead an implicit cast operator to the base type (and also an implementation for the comma operator, as present in all the other templates). 
\end{itemize}

Other representations of the internal storage of the vectors may require different template specializations.

\section{The front end}
The purpose of the front end is to translate OpenCL sources into the C++ IR described in the previous section. Since there are only a few OpenCL constructs that need to be transformed, this may initially seem like a task fit for a preprocessor. However, a correct implementation must use semantic analysis in order to differentiate between vector component accesses and accesses to members of user-defined structures that may have the same suffix (Listing \ref{lst:access}).

\begin{lstlisting}[label=lst:access, caption=Semantic analysis is a must]
struct my_struct {
	bool odd; 
};

/* If some_expression is of type struct my_struct, then the statement below should be 
 * left unchanged. If, however, some_expression is an OpenCL vector, then the 
 * statement should be replaced with a call to the Read() method. Without semantic 
 * analysis, it is impossible to determine what to do in this situation. */
[...]
(some_expression).odd;
\end{lstlisting}

Perhaps even more importantly, semantic analysis must be used in order to correctly identify errors in the original source. Although the design of the C++ IR, as described earlier, allows the StarCore compiler to catch some of these errors, it cannot cover all the possible cases. Significantly, it cannot cover the restrictions\footnote{Section \ref{section:ocl-language}.} imposed by the OpenCL language, such as the prohibition of recursion or of pointers to functions.

All these details are already implemented in Clang - the C, C++ and Objective-C front end for the LLVM\cite{http://llvm.org/} suite of compilers. Clang has a modular architecture, which makes it easy both to maintain and develop, and to integrate as a library into various applications. It also places great focus on emitting relevant diagnostics for user errors. These qualities, plus many more\cite{http://clang.llvm.org/features.html}, are leading to a widespread adoption of Clang across the industry. Of particular relevance to this thesis is the fact that the OpenCL implementations from ARM, Intel and Apple are built upon Clang\cite{http://clang-developers.42468.n3.nabble.com/How-much-of-OpenCL-C-is-currently-supported-by-Clang-td4025963.html}, and so is the Shevlin Park project described in Section \ref{section:oclalternatives}.

\subsection{Source to source transformations with Clang}
Clang keeps track of the exact source location for all the statements, expressions and even tokens it finds in the original code. This is useful for at least 2 things:
\begin{itemize}
\item Printing relevant diagnostics for errors in the source files: Clang places great stress on providing the exact location where the error occurred - see Listing \todo{Listing with clang error output}.
\item Doing source to source transformations.
\end{itemize}

Clang also provides a Rewriter class, with methods for inserting, removing and replacing text from the original source. This comes in very handy for source to source transformations, and it will be used in order to replace OpenCL-specific constructs with their C++ IR equivalent.

\subsection{OpenCL in Clang}
Clang offers support for the OpenCL language through all the phases of the compilation process. Due to its highly modular design, it also offers the possibility to customize any of these phases. However, in order to translate code into the C++ IR described in Section \ref{section:IR}, it is only necessary to modify the last one (i.e. the IR generation phase).

As is the case with most compilers \cite{engcompiler}, Clang builds an Abstract Syntax Tree (AST) of the original sources. An example of an AST generated by Clang can be seen in Listing \todo{Listing with AST example}.

The AST can be traversed by means of a RecursiveASTVisitor\footnote{en.wikipedia.org/wiki/Visitor\_pattern}. The RecursiveASTVisitor provides 3 kinds of methods for walking through the AST, which are called for each node in the AST:
\begin{itemize}
\item Visit* methods - these methods contain the action that must be taken for the current node.
\item WalkUpFrom* methods - these methods define the order in which the base classes of the current node must be visited (by default, the order is from the most generic to the most specific class in the inheritance hierarchy).
\item Traverse* methods - these methods define the order in which the child nodes are visited.
\end{itemize}

In order to achieve the translation of OpenCL sources into the C++ IR, it is necessary to inherit from RecursiveASTVisitor and override the Visit* methods corresponding to OpenCL-specific syntax. The transformations performed upon the original sources are as follows:
\begin{itemize}
\item OpenCL-specific qualifiers, such as \_\_kernel and the address space qualifiers, are removed\footnote{Without a proper runtime, it is impossible to determine how to handle the address space qualifiers. One approach would be to create separate segments in the linker configuration file and replace the qualifiers from the original sources with section attributes (\_\_attribute\_\_((section(segment\_name)))).}. This is done in the VisitDeclaratorDecl method.
\item References to the OpenCL vector type names are replaced with the equivalent C++ IR type names. This is done in the VisitDeclaratorDecl and VisitExplicitCastExpr methods, where the type of the node is ExtVectorType (to be described shortly).
\item Vector literals are transformed as described in Section \ref{section:IR} (that is, a dummy vector is introduced, and the rest falls into the hands of the overloaded comma operator). This takes place in the VisitCompoundLiteralExpr method.
\item Vector component accesses are replaced with calls to the Read or Write method. This is done in the VisitExtVectorElementExpr method.
\end{itemize}

Several things are worth mentioning here. First of all, OpenCL vectors are implemented as extended vectors, which is a GCC extension. The usage of this extension can be seen in Listing \ref{lst:extvector}.

\begin{lstlisting}[label=lst:extvector, caption=GCC extended vector extension]
typedef int int4 __attribute__((ext_vector_type(4)));
typedef int int2 __attribute__((ext_vector_type(2)));
\end{lstlisting}

The downside to this is that every source file that uses OpenCL vectors must somehow know about the corresponding typedefs. This can be achieved by having every such file include a header containing them, but a more elegant solution is to add the corresponding typedefs to the AST as though they were actually in the original file (obviously, this has to be done before parsing the file). As a side note, it is also necessary to add typedefs for the OpenCL unsigned data types (uchar, ushort etc.), as well as for the bool data type, which exists in OpenCL but not in standard C\footnote{Technically, the bool data type exists in the standard C header stdbool.h, but it's easier and faster to add it directly to the AST, along with the global constants true and false.}.

Secondly, overriding Visit* methods isn't always enough - sometimes it is necessary to override some Traverse* methods as well. For example, in the case of vector component accesses, Clang provides no means\footnote{To the best of our knowledge...} to determine whether it is a read access or a write access. Therefore, it is necessary to override the Traverse* methods for assignment operators in order to retain some context information. For instance, the TraverseBinAssign method (which corresponds to the binary assignment operator\footnote{=}) sets a flag before calling the Traverse method for the left-hand side of the operator and then resets it before traversing the right-hand side\footnote{This is enough to work for chained assignments, because the assignment operator is right-associative. If this weren't the case, one flag would not suffice.}. Other assignment operators, such as compound assignment operators\footnote{+=, *= etc.} or increment/decrement operators\footnote{++, $--$}, must be handled differently, as they require both a read access and a write access.

\todo{some sort of conclusion}